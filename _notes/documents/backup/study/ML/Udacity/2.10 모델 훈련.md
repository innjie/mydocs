## 데이터셋 나누기
모델 훈련의 첫번째 단계는 데이터 셋을 무작위로 분할하는 것이다. 따라서 훈련 중 일부 데이터를 숨겨 두면 모델을 생산에 투입하기 전에 데이터를 평가하는데 사용할 수 있다. 
특히 치우침 - 분산 트레이드 오프를 검사하기 위해 이 작업을 수행한다. 

데이터 셋을 분할하면 두가지 데이터 셋이 제공된다.

### 훈련 데이터셋
모델을 교육할 데이터. 대부분의 데이터가 포함된다. 많은 개발자들이 약 80%로 추산한다.

### 테스트 데이터셋
훈련 중에 모델에서 보류된 데이터는 모델이 새 데이터에 얼마나 잘 일반화가 되었는지 테스트하는데 사용된다.

<hr>

## **모델 훈련 용어**

모델 훈련 알고리즘은 일부 손실 기능을 최소화하기 위해 모델의 파라미터를 반복적으로 업데이트한다.

### 모델 파라미터
모델의 동작 방식을 변경하기 위해 훈련 알고리즘이 업데이트할 수 있는 설정 또는 구성이다. 문맥에 따라 가중치 및 편차와 같은 모델 매개변수를 설명하는데 사용되는 보다 구체적인 용어도 있다. 모델의 학습에 따라 변하는 값인 가중치는 신경망에 보다 구체적이다.

### 손실 함수 (Loss Function)
이 목표에서 모델의 거리를 코드화하는데 사용된다. 예를 들어 하루의 날씨를 기준으로 많은 수의 스노우콘 판매를 예측하려고 했다면 가능한 정확한 예측을 하는데 관심이 있을 것이다. 따라서 손실 함수는 모델의 예측 스노우콘 판매 수와 정확한 판매 수 사이의 평균거리로 정의할 수 있다. 스노우콘 예에서 볼 수 잇는 것은 두 점 사이의 차이이다.

#### 모두 합치기
전체 훈련 프로세스는 다음과 같다.
1. 훈련 데이터에 모델을 입력한다.
2. 결과에 대한 손실 함수를 계산한다. 
3. 손실을 줄이는 방향으로 모델 매개 변수를 갱신한다.

<hr>

## 전문가의 조언
1. 실무자는 모델 및 모델 훈련 알고리즘을 이미 구현한 머신러닝 프레임워크를 사용하는 경우가 많다. 이러한 기능을 처음부터 구현할 수 는 있지만, 새로운 모델이나 알고리즘을 개발하지 않는 한 구현할 필요가 없다.
2. 실무자는 모델 선택이라는 프로세스를 사용하여 사용할 모델 또는 모델을 결정한다. 기존 모델의 목록은 지속적으로 증가하고 있으며 숙련된 기계 학습 전문가도 기계학습 문제를 해결하면서 다양한 유형의 모델을 시도할 수 있다.
3. 하이퍼 파라미터는 훈련중에 변경되지 않지만 모델이 식별해야 하는 클러스터 수와 같이 모델이 얼마나 빨리 또는 얼마나 신뢰할 수 있는지에 영향을 미칠 수 잇는 모델의 설정이다.
4. 반복 준비

기계학습을 통한 실용적인 문제 해결은 거의 정확한 과학이 아니며, 잘못된 것으로 판명된 데이터 또는 문제에 대한 가정을 가질 수 있다. 시도하고, 성공을 측정하고, 반복하여 결과를 비교하는 습관을 기를 것.

<hr>

## **확장 학습**

### 1. 선형 모델
입문 과정에서 다루는 <mark style="background: #ABF7F7A6;">가장 일반적인 모델 </mark>중 하나인 선형 모델은 선형 함수를 통해 입력번호 세트와 출력번호 세트 사이의 관계를 간단히 설명한다. (y = mx + b 또는 x 대 y 차트의 선). 

분류작업은 종종 목표 등급에 포함될  확률로 해석되는 범위 (0, 1)에 선형 함수의 출력을 매핑하는 추가 변환을 추가하로직 모델을 사용한다. 선형 모델은 훈련속도가 빠르며 보다 복잡한 모델을 비교할 수 있는 훌륭한 기준을 제공한다. 좀 더 복잡한 모델에는 많은 비디어 버즈가 제공되지만 대부분의 새로운 문제에 대해서는 간단한 모델부터 시작하는게 좋다.

### 2. 트리 기반 모델
입문 과정에서 다루는 **두번째로 가장 일반적인 모델 유형**이다. 이들은 중첩된 if/else 블록의 매우 큰 구조를 구축하여 각 if/else 블록에서 월드를 서로 다른 영역으로 분할하여 분류하거나 회귀하는 방법을 학습한다. 훈련은 이러한 분할이 정확히 어디에서 발생하며 각 잎 영역에 어떤 값이 할당되는지 결정한다.

예를 들어, 조도 센서가 햇빛에 잇는지 그림자에 있는지 확인하려는 경우 최종 학습된 구성이 (sensor_value > 0.698)인 깊이 1 트리를 훈련한 다음 1을 반호나하고, 그렇지 않으면 0을 반환한다. 트리 기반 모델 XGBoost는 일반적으로 이러한 종류의 모델을 위한 기성 구현으로 사용되며 여기에 설명된 것 이상의 향상된 기능을 포함한다. 보다 복잡한 모델로 이동하기 전에 트리기반 모델을 사용해 기준선을 확보해야 한다.

### 3. 딥러닝 모델
매우 인기 잇고 강력한 딥러닝은 <mark style="background: #ABF7F7A6;">인간의 뇌가 어떻게 기능하는지에 대한 개념적 모델을 기반으로 한 현대적인 접근법</mark>이다. (신경 네트워크) 모델은 무게에 의해 함께 연결된 뉴런의 집합 (매우 단순한 계산 단위)으로 구성되어 있다. 훈련 과정에는 각 체중의 값을 찾는 것이 포함된다.

다양한 종류의 문제를 모델링하거나 다른 종류의 데이터를 처리하기 위해 다양한 신경 네트워크 구조가 결정되었다. 

#### FFNN (Feed Forward Neural Network)
신경 네트워크를 구성하는 가장 간단한 방법인 피드포워드 뉴럴 네트워크는 뉴런을 일련의 층으로 구조화하고, 한 층의 각 뉴런이 이전 층의 모든 뉴런에 가중치를 포함한다.

#### CNN (Convolutional Neural Networks)
중첩된 필터를 그리드로 구성된 데이터 위에 표시한다. 영상을 처리할 때 가장 일반적으로 사용되는 유형의 모델이다.

#### RNN (Recurrent Neural Networks) / **LSTM** (Long Short-Term Memory)
기존 컴퓨팅의 루프를 효과적으로 나타내도록 구성되며, 일부 개체에 대해 반복되는 동안 상태를 수집한다. 데이터 시퀀스를 처리하는데 사용할 수 있다.

<hr>

## Python 라이브러리를 사용한 기계 학습
보다 고전적인 모델(선형, 트리 기반)과 일반적인 ML 관련 툴 세트를 보려면 sickit-learn을 참고한다. 이 라이브러리의 웹 설명서는 `공간에 익숙해지는 사용자`를 위해 구성되어 있으며 매우 유용한 도구와 기술을 익힐 수 있다.

**딥러닝**의 경우, `mxnet`, `tensorflow`, `pytorch`가 가장 일반적인 세 라이브러리다. 대부분의 기계학습 요구 사항을 위해 각 요구사항은 기능 쌍으로 구성되어 있으며 동등한 기능을 갖추고 있다.

<hr>

#### **용어**

**하이퍼파라미터**
훈련중에 변경되지 않지만 모델이 식별해야 하는 클러스터 수와 같이 모델이 얼마나 빨리 또는 얼마나 신뢰할 수 있는지에 영향을 미칠 수 잇는 모델의 설정이다.

**손실 함수**
모델의 거리를 코드화하는데 사용

**훈련 모델**
모델의 훈련할 데이터. 대부분의 데이터가 포함된다.

**테스트 데이터셋**
훈련중 모델에서 보류된 데이터는 모델이 새 데이터에 얼마나 잘 일반화되는지 테스트하는데 사용된다.

**모델 파라미터**
모델의 동작방식을 변경하기 위해 훈련 알고리즘이 업데이트할 수 있는 설정 또는 구성
